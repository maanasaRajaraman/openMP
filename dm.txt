# !pip install ucimlrepo

from ucimlrepo import fetch_ucirepo
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder
from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif
from sklearn.decomposition import PCA
import numpy as np

sns.set()
credit_approval = fetch_ucirepo(id=27)
df = pd.DataFrame(data=credit_approval.data.features)

df_num = df.select_dtypes(include=['int64', 'float64'])
df_cat = df.select_dtypes(include=['object'])

# Q1 - Identify the types of attributes in the dataset
print("Dataset Info:")
df.info()

# Q2 - Analyze the spread and distribution of numerical attributes
print("\nStatistical Summary of Numerical Attributes:")
print(df_num.describe())

# Q3 - Scatter plots for all combinations of numerical attributes
sns.pairplot(df_num)
plt.show()

# Q4 - Interpret scatter plots

# Q5 - Generate boxplot to identify outliers
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_num, orient='h')
plt.title("Boxplot of Numerical Attributes")
plt.show()

# Q6 - Use catplot() to visualize categorical attributes
for col in df_cat.columns:
    sns.catplot(x=col, kind="count", data=df_cat)
    plt.title(f"Count Plot for {col}")
    plt.show()

# Q7 - Analyze similarities/dissimilarities of numerical attributes
correlation_matrix = df_num.corr()
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.title("Correlation Matrix of Numerical Attributes")
plt.show()

# Q8 - Handle missing values
print("Missing Values Before Imputation:")
print(df.isnull().sum())

df_num.fillna(df_num.mean(), inplace=True)
df_cat.fillna(df_cat.mode().iloc[0], inplace=True)

print("\nMissing Values After Imputation:")
print(df.isnull().sum())

# Q9 - Remove noisy data using equal-width or equal-frequency binning
bins = 4
df_num_binned = df_num.copy()
for col in df_num.columns:
    df_num_binned[col] = pd.cut(df_num[col], bins=bins, labels=False)

print("\nEqual Width Binned Numerical Data:")
print(df_num_binned.head())

# Q10 - Encode categorical attributes
le = LabelEncoder()
for col in df_cat.columns:
    df_cat[col] = le.fit_transform(df_cat[col])

print("\nEncoded Categorical Data:") 
print(df_cat.head())

# Q11 - Normalize attributes
min_max_scaler = MinMaxScaler()
z_score_scaler = StandardScaler()

df_num_minmax = pd.DataFrame(min_max_scaler.fit_transform(df_num), columns=df_num.columns)
df_num_zscore = pd.DataFrame(z_score_scaler.fit_transform(df_num), columns=df_num.columns)

print("\nMin-Max Normalized Data:")
print(df_num_minmax.head())

print("\nZ-Score Normalized Data:")
print(df_num_zscore.head())

# Q12 - Feature selection
X = pd.concat([df_num, df_cat], axis=1)
y = credit_approval.data.targets
y = le.fit_transform(y)

# Chi-squared
selector_chi2 = SelectKBest(chi2, k=5).fit(X, y)
print("Chi-squared Selected Features:", X.columns[selector_chi2.get_support()])

# ANOVA F-value
selector_fvalue = SelectKBest(f_classif, k=5).fit(df_num, y)
print("ANOVA Selected Features:", df_num.columns[selector_fvalue.get_support()])

# Mutual Information
selector_mutual = SelectKBest(mutual_info_classif, k=5).fit(X, y)
print("Mutual Information Selected Features:", X.columns[selector_mutual.get_support()])

# Q13 - Dimensionality Reduction
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', s=10)
plt.title("PCA Visualization")
plt.xlabel("Principal Component 1")
plt.ylabel("Principal Component 2")
plt.colorbar(label='Target')
plt.show()

# Q14 - Correlation techniques
correlations = pd.DataFrame(df_num.corrwith(pd.Series(y, index=df_num.index)), columns=['Correlation'])
print("\nCorrelation of Features with Target Variable:")
print(correlations)

# Q15 - Visualize reduced dataset
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='coolwarm', alpha=0.7)
plt.title("Reduced Dataset Visualization")
plt.show()

# Q16 - Additional observations
# - Analyze feature importance from PCA or clustering.
# - Any patterns seen in scatter plots, heatmaps, or binned data.


#PS 2

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt

sns.set()

#q1
''' age =[13, 40, 45, 16, 22, 25, 25, 22, 25, 25, 30, 52, 70, 33, 35, 15, 35, 36, 33, 16, 19,
20, 35, 35, 46, 20, 21]

age = pd.DataFrame(age, columns=['age'])
sns.histplot(data=age, x='age')

#box plot
sns.boxplot(data=age)

#pie chart using matplotlib
count = age.value_counts()
plt.pie(count, labels=count.index)
plt.show()
'''

#q2
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/iris.csv")
plt.figure(figsize=(10,10))
# a ) Scatter plots based on the sepal width and sepal length
plt.subplot(2,2,1)
sns.scatterplot(x='sepal_length', y='sepal_width', hue='species', data=df, s=8)

# b) Compare the petal length of various species
plt.subplot(2,2,2)
sns.scatterplot(x='petal_length', y='petal_width', hue='species', data=df, s=10)

# c) Swarm Plots
plt.subplot(2,2,3)
sns.swarmplot(x='species', y='petal_width', data=df, s=2)

plt.subplot(2,2,4)
sns.swarmplot(x='species', y='sepal_width', data=df, s=2)

print("Range of Sepal width : ", df['sepal_width'].max() - df['sepal_width'].min())
print("Range of Petal width : ", df['petal_width'].max() - df['petal_width'].min())
print("Sepal Width with highest frequency: ", df['sepal_width'].value_counts().idxmax())
print("Petal Width with highest frequency: ", df['petal_width'].value_counts().idxmax())

'''
# d) Swarm plot for sepal Length
sns.swarmplot(x='species', y='sepal_length', data=df)

# e) histogram and density plots for sepal width
plt.subplot(2,2,1)
sns.histplot(x='sepal_width', data=df, kde=True)

#q3 Box plots of all the features, excluding the class, in a single frame

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/iris.csv")
sns.boxplot(data=df.drop(['species'], axis=1))

# Violin plot of petal length
sns.violinplot(x='species', y='petal_length', data=df)
'''


import pandas as pd
import numpy as np
from scipy import stats

#q1
'''
df = (pd.read_csv("Automobile_spare.csv"))

df = pd.Series(df.columns)
print(df.min())

print("Maximum spares sold: ", float(df.max())*100)
print("Number of days maximum spares sold: ", df.loc[df == df.max()].size)

print("Number of days with no sales: ", df.loc[df == df.min()].size)

df = df.astype(float)
print("Number of spares sold in first half: ", round(df.iloc[:len(df)//2].sum()*100, 0))
print("Number of spares sold in second half: ", round(df.iloc[len(df)//2:].sum()*100, 0))


print("Maximum sales in first half: ", round(df.iloc[:len(df)//2].max()*100, 0))
print("Maximum sales in second half: ", round(df.iloc[len(df)//2:].max()*100, 0))
'''
#q2
'''
data = [13, 40, 45, 16, 22, 25, 25, 22, 25, 25, 30, 52, 70, 33, 35, 15, 35, 36, 33, 16, 19,
20, 35, 35, 46, 20, 21]

print("Mean : ", np.mean(data))
print("Median :", np.median(data))
print("Mode :", stats.mode(data))

data.sort()
print("Midrange ", (data[0]+data[len(data)-1])/2)

df = {'Num' : [13, 40, 45, 16, 22, 25, 25, 22, 25, 25, 30, 52, 70, 33, 35, 15, 35, 36, 33, 16, 19,
20, 35, 35, 46, 20, 21]}
df = pd.DataFrame(df)

print("\nQuartiles")
print(df['Num'].quantile([0.25,0.5,0.75]))

boxplot = df.boxplot(column=['Num'])
print(boxplot)  

'''

# q3

df = (pd.read_csv("2015_16_Statewise_Secondary.csv"))
# print(df)
print("Size : ", df.shape)

nanValues = df.isnull().sum().sort_values(ascending = False)
print(nanValues)

stateCln = df['statname']
print("\nNumber of states : ", len(stateCln))

print("\nLiteracy Rate ")

maxLR = (df.max(axis=0)['literacy_rate'])
minLR = (df.min(axis=0)['literacy_rate'])

print("Maximum: ", df.loc[df['literacy_rate'] == maxLR, 'statname'].iloc[0]) #['statname'])
print("Minimum: ", df.loc[df['literacy_rate'] == minLR,'statname'].iloc[0])


print ("Schools have single teacher in secondary level", df['sing_tch_sch_5']. sum() )

